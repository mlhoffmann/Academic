{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential, load_model, model_from_json\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import matplotlib\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import MaxPooling1D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df['Data'], format='%Y.%m.%d.%H.%M.%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Data',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['2018-08-01 12:00:00':'2018-10-01 12:00:00'] # Período onde o compressor operou até parar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[['X27','X26','X25','X10']]\n",
    "df_2 = df[['X14','X9','X18','X15','X19','X17']]\n",
    "df_3 = df[['X20','X16','X24','X23','X13','X22','X6','X1','X21','X5','X7']]\n",
    "df_4 = df[['X12','X4','X8']]\n",
    "df_5 = df[['X2','X3','X11']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os dados de treino e de teste:\n",
    "========================================\n",
    "Este período foi selecionado devido ser onde o compressor operou de forma constante sem falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot variables to model\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5,1, sharex=True)\n",
    "ax1.plot(df_1)\n",
    "ax1.legend(df_1, loc='upper right', bbox_to_anchor=(0.564, 0.5, 0.5, 0.5))\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(df_2)\n",
    "ax2.legend(df_2, loc='upper right', bbox_to_anchor=(0.564, 0.5, 0.5, 0.5))\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.plot(df_3)\n",
    "ax3.legend(df_3, loc='upper right', bbox_to_anchor=(0.564, 0.5, 0.5, 0.5))\n",
    "ax3.grid(True)\n",
    "\n",
    "ax4.plot(df_4)\n",
    "ax4.legend(df_4, loc='upper right', bbox_to_anchor=(0.564, 0.5, 0.5, 0.5))\n",
    "ax4.grid(True)\n",
    "\n",
    "ax5.plot(df_5)\n",
    "ax5.legend(df_5, loc='upper right', bbox_to_anchor=(0.564, 0.5, 0.5, 0.5))\n",
    "ax5.grid(True)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(top=5, bottom=0.15, left=0.10, right=2.3, hspace=0.071,wspace=0.2)\n",
    "fig.savefig('var_plt.pdf',  dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df['2018-08-01 12:00:00':'2018-09-20 00:00:00'] # Período onde o compressor operou sem problemas\n",
    "test =  df['2018-09-20 00:00:00':'2018-10-01 12:00:00'] # Período antes da falha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Period = pd.concat([train,test])\n",
    "ax = Period.plot(figsize = (14,6), legend = None)\n",
    "plt.axvline('2018-09-20 00:00:00', ymin=-0.01, ymax = 4000, linewidth=2,color = 'k')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.58, 0.5, 0.5, 0.5))\n",
    "plt.text('2018-09-21 00:00:00',2250, 'Test dataset leading \\n up to the failure',  ha=\"left\", verticalalignment='baseline',fontsize = 14)\n",
    "plt.text('2018-08-15 00:00:00',2250, 'Dataset for training under normal operating conditions', ha=\"left\", verticalalignment='baseline',fontsize = 14)\n",
    "\n",
    "ax.set_xlabel('Analysis period', color ='k',fontsize = 14)\n",
    "ax.xaxis.set_label_coords(0.45, -0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Normalizar dados:**\n",
    "\n",
    "Em seguida, uso as ferramentas de pré-processamento do Scikit-learn para dimensionar as variáveis de entrada do modelo. \n",
    "O “MinMaxScaler” simplesmente redimensiona os dados para estar no intervalo [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.transform(test)\n",
    "scaler_filename = \"scaler_data\"\n",
    "dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão para float32 \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshape inputs for CNN \n",
    "X_train_cnn = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "print(\"Training data shape:\", X_train_cnn.shape)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "print(\"Test data shape:\", X_test_cnn.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para teste\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(train), \n",
    "                              columns=train.columns, \n",
    "                              index=train.index)\n",
    "# Utilizado Random shuffle nos dados de treinamento para selecionar de forma aleatória\n",
    "X_train.sample(frac=1)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(test), \n",
    "                             columns=test.columns, \n",
    "                             index=test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros do modelo\n",
    "\n",
    "# Função de Ativação\n",
    "ACT_FUNC = 'elu'  \n",
    "\n",
    "# Dimensões input\n",
    "INPUT_SHAPE = (X_train.shape[1],1) \n",
    "\n",
    "# Tamanho do batch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Dropout\n",
    "DROPOUT_RATE = 0.1 \n",
    "\n",
    "# Número de épocas\n",
    "EPOCHS = 150\n",
    "\n",
    "# Dados para Split\n",
    "SPLIT_VAL=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo CNN\n",
    "def anomaly_model(input_shape):\n",
    "    model = Sequential()\n",
    "    np.random.seed(42)\n",
    "      \n",
    "    # Primeira camada convolucional \n",
    "    model.add(Conv1D(128, kernel_size = 7, padding = 'same', input_shape = INPUT_SHAPE))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(ACT_FUNC))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "\n",
    "\n",
    "    # Segunda camada convolucional \n",
    "    model.add(Conv1D(64, kernel_size = 5, padding = 'same')) \n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation(ACT_FUNC))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "\n",
    "    \n",
    "    # Terceira camada convolucional (encouder)\n",
    "    model.add(Conv1D(32, kernel_size = 3,  padding = 'same'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation(ACT_FUNC))\n",
    "\n",
    "    model.add(Conv1D(32, kernel_size = 3,  padding = 'same'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation(ACT_FUNC))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "      \n",
    "  \n",
    "    # Quarta camada convolucional \n",
    "    model.add(Conv1D(64, kernel_size = 5, padding = 'same'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation(ACT_FUNC))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "\n",
    "    # Quinta camada convolucional \n",
    "    model.add(Conv1D(128, kernel_size = 7, padding = 'same'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation(ACT_FUNC))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Sexta camada totalmente conectada    \n",
    "    model.add(Dense(100, kernel_initializer='glorot_uniform' , activation = 'relu'))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "\n",
    "    model.add(Dense(X_train.shape[1], activation = ACT_FUNC))\n",
    "        \n",
    "    # Otimizador\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checando a memória da GPU\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parar recuso da memória da GPU\n",
    "#pid = 21576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.kill(pid,pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Controle do modelo\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=7, verbose=1, mode='min')\n",
    "\n",
    "# fit the model to the data\n",
    "model = anomaly_model(INPUT_SHAPE)\n",
    "history = model.fit(X_train_cnn, X_train, epochs=EPOCHS, callbacks= [monitor] , batch_size=BATCH_SIZE,\n",
    "                    validation_split=SPLIT_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save all model information, including weights, in h5 format\n",
    "model.save(\"Anomaly_model.h5\",include_optimizer=True)\n",
    "\n",
    "\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(history.history['loss'],'b',label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss, [mse]')\n",
    "plt.ylim([0,.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "X_pred = model.predict(np.array(X_train_cnn))\n",
    "X_pred = pd.DataFrame(X_pred, columns=X_train.columns)\n",
    "X_pred.index = X_train.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_train.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "             bins = 10, \n",
    "             axlabel =\"Loss mae, training set\",\n",
    "             kde= True,\n",
    "            color = 'blue');\n",
    "plt.xlim([0.0,.16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.hist(scored['Loss_mae'], bins=50)\n",
    "plt.xlabel(\"Train mae loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    " \n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.round(np.max(scored['Loss_mae']),3)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_test_cnn))\n",
    "X_pred = pd.DataFrame(X_pred, columns=X_test.columns)\n",
    "X_pred.index = X_test.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_test.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = threshold\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "\n",
    "sns.set(font_scale=1.2) \n",
    "plt.figure(figsize = (8,4))\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "             bins = 10, \n",
    "             axlabel =\"Loss mae, test set\", \n",
    "             kde= True,\n",
    "            color = 'blue');\n",
    "plt.xlim([0.0,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = model.predict(np.array(X_train_cnn))\n",
    "X_pred_train = pd.DataFrame(X_pred_train, columns=X_train.columns)\n",
    "X_pred_train.index = X_train.index\n",
    "\n",
    "scored_train = pd.DataFrame(index=X_train.index)\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = threshold\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = scored.plot(logy=True,  figsize = (14,7), ylim = [1e-3,1e2],  color = ['blue','red'])\n",
    "ax.annotate('Anomaly identified',fontsize = 14, xy=('2018-09-16 12:00:00', 0.03), xytext=('2018-09-01 11:00:00', 0.005),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, color = 'r', ec ='k'))\n",
    "\n",
    "ax.annotate('Compressor failure',fontsize = 14, xy=('2018-10-01 12:00:00', 0.18), xytext=('2018-09-15 11:00:00', 3.5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, color = 'r',ec ='k'))\n",
    "\n",
    "plt.legend(loc='upper left', fontsize = 14)\n",
    "plt.axvline('2018-10-01 11:00:00', linewidth = 3, color = 'k', linestyle = \"--\")\n",
    "ax.set_ylabel('Reconstruction loss', color ='k',fontsize = 14)\n",
    "\n",
    "ax.set_xlabel('Analysis period', color ='k',fontsize = 14)\n",
    "ax.xaxis.set_label_coords(0.45, -0.18)\n",
    "fig.savefig('fail.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenado os dados de treino e teste para comparar com a função gerada pelo modelo\n",
    "df_TraTes = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenado os dados de treino e teste para comparar com a função gerada pelo modelo\n",
    "df_TraTes = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o Subset do resultado \n",
    "df0 = pd.DataFrame(scored.Loss_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando o resultado dos Scores\n",
    "df_fim = pd.merge(df_TraTes,df0, on=[\"Data\"])\n",
    "df_fim = df_fim.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red\">FEATURE IMPORTANCE</span>\n",
    "============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_fim.iloc[:,-1]\n",
    "X = df_fim.iloc[:,0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc = {'figure.figsize':(30, 25)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating a feature importance dataframe\n",
    "def imp_df(column_names, importances):\n",
    "    df = pd.DataFrame({'feature': column_names,\n",
    "                       'feature_importance': importances}) \\\n",
    "           .sort_values('feature_importance', ascending = False) \\\n",
    "           .reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "# plotting a feature importance dataframe (horizontal barchart)\n",
    "def var_imp_plot(imp_df, title):\n",
    "    imp_df.columns = ['feature', 'feature_importance']\n",
    "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n",
    "       .set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestRegressor(n_estimators = 150,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), \n",
    "                                                                                             rf.oob_score_,\n",
    "                                                                                             rf.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imp = imp_df(X_train.columns, rf.feature_importances_)\n",
    "#base_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [11, 10]\n",
    "var_imp_plot(base_imp, \"Feature importance by - Tag's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)\n",
    "perm_imp_rfpimp.reset_index(drop = False, inplace = True) #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [11, 10]\n",
    "var_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 100).fit(X_train, y_train)\n",
    "perm_imp_eli5 = imp_df(X_train.columns, perm.feature_importances_)\n",
    "var_imp_plot(perm_imp_eli5, 'Permutation feature importance Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(perm,show_feature_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(n_estimators=150,\n",
    "                           booster='gbtree',\n",
    "                           importance_type='gain',\n",
    "                           gpu_id=-1,\n",
    "                           verbosity=1,\n",
    "                           random_state = 42)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R^2 Training Score: {:.2f}  \\nR^2 Validation Score: {:.2f}'.format(xgb.score(X_train, y_train), \n",
    "                                                                          xgb.score(X_valid, y_valid)))                        \n",
    "                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imp_xgb = imp_df(X_train.columns, xgb.feature_importances_)\n",
    "base_imp_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [11, 10]\n",
    "var_imp_plot(base_imp_xgb, \"Feature importance by - Tag's - xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_xgb = PermutationImportance(xgb,  cv = None, refit = False, n_iter = 150).fit(X_train, y_train)\n",
    "perm_imp_eli5_xgb = imp_df(X_train.columns, perm_xgb.feature_importances_)\n",
    "var_imp_plot(perm_imp_eli5_xgb, 'Permutation feature importance xgboost ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do modelo com dados de 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df['Data'], format='%Y.%m.%d.%H.%M.%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Data',1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.abs()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize = (14,6))\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.58, 0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df['2019-08-25 00:00:00':'2019-09-20 18:30:00'] # Período onde o compressor operou sem problemas\n",
    "test =  df['2019-09-20 18:30:00':'2019-10-01 18:30:00'] # Período antes da falha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot(figsize = (14,6))\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.58, 0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train)\n",
    "X_test = scaler.transform(test)\n",
    "scaler_filename = \"scaler_data\"\n",
    "dump(scaler, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão para float32 \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshape inputs for CNN \n",
    "X_train_cnn = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "print(\"Training data shape:\", X_train_cnn.shape)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "print(\"Test data shape:\", X_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para teste\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(train), \n",
    "                              columns=train.columns, \n",
    "                              index=train.index)\n",
    "# Utilizado Random shuffle nos dados de treinamento para selecionar de forma aleatória\n",
    "X_train.sample(frac=1)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(test), \n",
    "                             columns=test.columns, \n",
    "                             index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('Anomaly_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_train_cnn))\n",
    "X_pred = pd.DataFrame(X_pred, columns=X_train.columns)\n",
    "X_pred.index = X_train.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_train.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
    "plt.figure(figsize = (8,4))\n",
    "sns.distplot(scored['Loss_mae'],\n",
    "             bins = 5, \n",
    "             kde= True,\n",
    "            color = 'blue');\n",
    "plt.xlim([0.0,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(np.array(X_test_cnn))\n",
    "X_pred = pd.DataFrame(X_pred, columns=X_test.columns)\n",
    "X_pred.index = X_test.index\n",
    "\n",
    "scored = pd.DataFrame(index=X_test.index)\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
    "scored['Threshold'] = threshold\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = model.predict(np.array(X_train_cnn))\n",
    "X_pred_train = pd.DataFrame(X_pred_train, columns=X_train.columns)\n",
    "X_pred_train.index = X_train.index\n",
    "\n",
    "scored_train = pd.DataFrame(index=X_train.index)\n",
    "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
    "scored_train['Threshold'] = threshold\n",
    "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
    "scored = pd.concat([scored_train, scored])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored.plot(logy=True,  figsize = (10,6), ylim = [1e-3,1e2], color = ['blue','red'])\n",
    "#plt.axvline('2018-09-20 00:00:00', ymin=0.2, ymax = 0.8, linewidth=3,color = 'g')\n",
    "#plt.text('2018-09-20 00:00:00',0.2, 'Anomaly detection',  ha=\"right\", rotation=90,  multialignment=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenado os dados de treino e teste para comparar com a função gerada pelo modelo\n",
    "df_TraTes = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando o Subset do resultado \n",
    "df0 = pd.DataFrame(scored.Loss_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando o resultado dos Scores\n",
    "df_fim = pd.merge(df_TraTes,df0, on=[\"Data\"])\n",
    "df_fim = df_fim.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_fim.iloc[:,-1]\n",
    "X = df_fim.iloc[:,0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc = {'figure.figsize':(30, 25)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating a feature importance dataframe\n",
    "def imp_df(column_names, importances):\n",
    "    df = pd.DataFrame({'feature': column_names,\n",
    "                       'feature_importance': importances}) \\\n",
    "           .sort_values('feature_importance', ascending = False) \\\n",
    "           .reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "# plotting a feature importance dataframe (horizontal barchart)\n",
    "def var_imp_plot(imp_df, title):\n",
    "    imp_df.columns = ['feature', 'feature_importance']\n",
    "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n",
    "       .set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestRegressor(n_estimators = 150,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), \n",
    "                                                                                             rf.oob_score_,\n",
    "                                                                                             rf.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_imp = imp_df(X_train.columns, rf.feature_importances_)\n",
    "#base_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [11, 10]\n",
    "var_imp_plot(base_imp, \"Feature importance by - Tag's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipe.fullSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1599499045216",
   "language": "python",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}